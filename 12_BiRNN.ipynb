{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-4ab28ef6bbe1>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/taeho/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/taeho/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/taeho/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/taeho/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/taeho/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-4ab28ef6bbe1>:51: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "WARNING:tensorflow:From <ipython-input-1-4ab28ef6bbe1>:70: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Iter 1280, Minibatch Loss= 2.441803, Training Accuracy= 0.22656\n",
      "Iter 2560, Minibatch Loss= 1.272413, Training Accuracy= 0.59375\n",
      "Iter 3840, Minibatch Loss= 0.734309, Training Accuracy= 0.75781\n",
      "Iter 5120, Minibatch Loss= 0.859371, Training Accuracy= 0.66406\n",
      "Iter 6400, Minibatch Loss= 0.617690, Training Accuracy= 0.78125\n",
      "Iter 7680, Minibatch Loss= 0.529950, Training Accuracy= 0.83594\n",
      "Iter 8960, Minibatch Loss= 0.388442, Training Accuracy= 0.90625\n",
      "Iter 10240, Minibatch Loss= 0.364923, Training Accuracy= 0.90625\n",
      "Iter 11520, Minibatch Loss= 0.201856, Training Accuracy= 0.92969\n",
      "Iter 12800, Minibatch Loss= 0.312584, Training Accuracy= 0.90625\n",
      "Iter 14080, Minibatch Loss= 0.287344, Training Accuracy= 0.92188\n",
      "Iter 15360, Minibatch Loss= 0.291218, Training Accuracy= 0.89844\n",
      "Iter 16640, Minibatch Loss= 0.238231, Training Accuracy= 0.92969\n",
      "Iter 17920, Minibatch Loss= 0.174006, Training Accuracy= 0.92969\n",
      "Iter 19200, Minibatch Loss= 0.195694, Training Accuracy= 0.93750\n",
      "Iter 20480, Minibatch Loss= 0.259647, Training Accuracy= 0.91406\n",
      "Iter 21760, Minibatch Loss= 0.127618, Training Accuracy= 0.96875\n",
      "Iter 23040, Minibatch Loss= 0.202481, Training Accuracy= 0.92969\n",
      "Iter 24320, Minibatch Loss= 0.116472, Training Accuracy= 0.96094\n",
      "Iter 25600, Minibatch Loss= 0.205198, Training Accuracy= 0.92188\n",
      "Iter 26880, Minibatch Loss= 0.154027, Training Accuracy= 0.93750\n",
      "Iter 28160, Minibatch Loss= 0.218819, Training Accuracy= 0.92969\n",
      "Iter 29440, Minibatch Loss= 0.162185, Training Accuracy= 0.94531\n",
      "Iter 30720, Minibatch Loss= 0.146145, Training Accuracy= 0.96094\n",
      "Iter 32000, Minibatch Loss= 0.118475, Training Accuracy= 0.96094\n",
      "Iter 33280, Minibatch Loss= 0.073246, Training Accuracy= 0.97656\n",
      "Iter 34560, Minibatch Loss= 0.048376, Training Accuracy= 0.99219\n",
      "Iter 35840, Minibatch Loss= 0.075482, Training Accuracy= 0.97656\n",
      "Iter 37120, Minibatch Loss= 0.110379, Training Accuracy= 0.94531\n",
      "Iter 38400, Minibatch Loss= 0.059231, Training Accuracy= 0.97656\n",
      "Iter 39680, Minibatch Loss= 0.177722, Training Accuracy= 0.98438\n",
      "Iter 40960, Minibatch Loss= 0.173421, Training Accuracy= 0.94531\n",
      "Iter 42240, Minibatch Loss= 0.062111, Training Accuracy= 0.96875\n",
      "Iter 43520, Minibatch Loss= 0.096004, Training Accuracy= 0.97656\n",
      "Iter 44800, Minibatch Loss= 0.080520, Training Accuracy= 0.97656\n",
      "Iter 46080, Minibatch Loss= 0.031041, Training Accuracy= 0.98438\n",
      "Iter 47360, Minibatch Loss= 0.040895, Training Accuracy= 0.98438\n",
      "Iter 48640, Minibatch Loss= 0.092950, Training Accuracy= 0.96875\n",
      "Iter 49920, Minibatch Loss= 0.088696, Training Accuracy= 0.96875\n",
      "Iter 51200, Minibatch Loss= 0.081630, Training Accuracy= 0.96875\n",
      "Iter 52480, Minibatch Loss= 0.045919, Training Accuracy= 0.98438\n",
      "Iter 53760, Minibatch Loss= 0.098960, Training Accuracy= 0.97656\n",
      "Iter 55040, Minibatch Loss= 0.115496, Training Accuracy= 0.95312\n",
      "Iter 56320, Minibatch Loss= 0.099143, Training Accuracy= 0.98438\n",
      "Iter 57600, Minibatch Loss= 0.048812, Training Accuracy= 0.98438\n",
      "Iter 58880, Minibatch Loss= 0.032599, Training Accuracy= 0.98438\n",
      "Iter 60160, Minibatch Loss= 0.064882, Training Accuracy= 0.96875\n",
      "Iter 61440, Minibatch Loss= 0.033839, Training Accuracy= 0.99219\n",
      "Iter 62720, Minibatch Loss= 0.092667, Training Accuracy= 0.97656\n",
      "Iter 64000, Minibatch Loss= 0.061503, Training Accuracy= 0.97656\n",
      "Iter 65280, Minibatch Loss= 0.064778, Training Accuracy= 0.96094\n",
      "Iter 66560, Minibatch Loss= 0.009554, Training Accuracy= 1.00000\n",
      "Iter 67840, Minibatch Loss= 0.077748, Training Accuracy= 0.96875\n",
      "Iter 69120, Minibatch Loss= 0.052634, Training Accuracy= 0.97656\n",
      "Iter 70400, Minibatch Loss= 0.058845, Training Accuracy= 0.98438\n",
      "Iter 71680, Minibatch Loss= 0.077677, Training Accuracy= 0.98438\n",
      "Iter 72960, Minibatch Loss= 0.044663, Training Accuracy= 0.99219\n",
      "Iter 74240, Minibatch Loss= 0.115229, Training Accuracy= 0.97656\n",
      "Iter 75520, Minibatch Loss= 0.030236, Training Accuracy= 0.99219\n",
      "Iter 76800, Minibatch Loss= 0.090076, Training Accuracy= 0.95312\n",
      "Iter 78080, Minibatch Loss= 0.035962, Training Accuracy= 0.98438\n",
      "Iter 79360, Minibatch Loss= 0.101466, Training Accuracy= 0.96875\n",
      "Iter 80640, Minibatch Loss= 0.143346, Training Accuracy= 0.93750\n",
      "Iter 81920, Minibatch Loss= 0.066469, Training Accuracy= 0.99219\n",
      "Iter 83200, Minibatch Loss= 0.029397, Training Accuracy= 1.00000\n",
      "Iter 84480, Minibatch Loss= 0.054594, Training Accuracy= 0.97656\n",
      "Iter 85760, Minibatch Loss= 0.029093, Training Accuracy= 1.00000\n",
      "Iter 87040, Minibatch Loss= 0.019146, Training Accuracy= 1.00000\n",
      "Iter 88320, Minibatch Loss= 0.098269, Training Accuracy= 0.96875\n",
      "Iter 89600, Minibatch Loss= 0.078628, Training Accuracy= 0.98438\n",
      "Iter 90880, Minibatch Loss= 0.065995, Training Accuracy= 0.99219\n",
      "Iter 92160, Minibatch Loss= 0.034059, Training Accuracy= 0.97656\n",
      "Iter 93440, Minibatch Loss= 0.049186, Training Accuracy= 0.97656\n",
      "Iter 94720, Minibatch Loss= 0.016550, Training Accuracy= 1.00000\n",
      "Iter 96000, Minibatch Loss= 0.050863, Training Accuracy= 0.98438\n",
      "Iter 97280, Minibatch Loss= 0.108466, Training Accuracy= 0.96875\n",
      "Iter 98560, Minibatch Loss= 0.040931, Training Accuracy= 0.98438\n",
      "Iter 99840, Minibatch Loss= 0.034610, Training Accuracy= 0.99219\n",
      "Iter 101120, Minibatch Loss= 0.040426, Training Accuracy= 0.99219\n",
      "Iter 102400, Minibatch Loss= 0.070907, Training Accuracy= 0.97656\n",
      "Iter 103680, Minibatch Loss= 0.024412, Training Accuracy= 0.99219\n",
      "Iter 104960, Minibatch Loss= 0.015459, Training Accuracy= 1.00000\n",
      "Iter 106240, Minibatch Loss= 0.029845, Training Accuracy= 0.99219\n",
      "Iter 107520, Minibatch Loss= 0.038095, Training Accuracy= 0.99219\n",
      "Iter 108800, Minibatch Loss= 0.044327, Training Accuracy= 0.99219\n",
      "Iter 110080, Minibatch Loss= 0.091580, Training Accuracy= 0.97656\n",
      "Iter 111360, Minibatch Loss= 0.026472, Training Accuracy= 0.99219\n",
      "Iter 112640, Minibatch Loss= 0.026975, Training Accuracy= 0.99219\n",
      "Iter 113920, Minibatch Loss= 0.082639, Training Accuracy= 0.99219\n",
      "Iter 115200, Minibatch Loss= 0.017536, Training Accuracy= 0.99219\n",
      "Iter 116480, Minibatch Loss= 0.013214, Training Accuracy= 1.00000\n",
      "Iter 117760, Minibatch Loss= 0.013246, Training Accuracy= 1.00000\n",
      "Iter 119040, Minibatch Loss= 0.015876, Training Accuracy= 0.99219\n",
      "Iter 120320, Minibatch Loss= 0.031579, Training Accuracy= 1.00000\n",
      "Iter 121600, Minibatch Loss= 0.038114, Training Accuracy= 0.98438\n",
      "Iter 122880, Minibatch Loss= 0.065357, Training Accuracy= 0.98438\n",
      "Iter 124160, Minibatch Loss= 0.052072, Training Accuracy= 0.98438\n",
      "Iter 125440, Minibatch Loss= 0.057946, Training Accuracy= 0.96875\n",
      "Iter 126720, Minibatch Loss= 0.014724, Training Accuracy= 1.00000\n",
      "Iter 128000, Minibatch Loss= 0.080662, Training Accuracy= 0.97656\n",
      "Iter 129280, Minibatch Loss= 0.033700, Training Accuracy= 1.00000\n",
      "Iter 130560, Minibatch Loss= 0.028483, Training Accuracy= 0.98438\n",
      "Iter 131840, Minibatch Loss= 0.018480, Training Accuracy= 1.00000\n",
      "Iter 133120, Minibatch Loss= 0.025889, Training Accuracy= 0.99219\n",
      "Iter 134400, Minibatch Loss= 0.094252, Training Accuracy= 0.98438\n",
      "Iter 135680, Minibatch Loss= 0.049578, Training Accuracy= 0.98438\n",
      "Iter 136960, Minibatch Loss= 0.056133, Training Accuracy= 0.98438\n",
      "Iter 138240, Minibatch Loss= 0.042399, Training Accuracy= 0.98438\n",
      "Iter 139520, Minibatch Loss= 0.085160, Training Accuracy= 0.96094\n",
      "Iter 140800, Minibatch Loss= 0.044082, Training Accuracy= 0.98438\n",
      "Iter 142080, Minibatch Loss= 0.007323, Training Accuracy= 1.00000\n",
      "Iter 143360, Minibatch Loss= 0.123899, Training Accuracy= 0.97656\n",
      "Iter 144640, Minibatch Loss= 0.045380, Training Accuracy= 0.99219\n",
      "Iter 145920, Minibatch Loss= 0.042242, Training Accuracy= 0.98438\n",
      "Iter 147200, Minibatch Loss= 0.021375, Training Accuracy= 1.00000\n",
      "Iter 148480, Minibatch Loss= 0.069211, Training Accuracy= 0.98438\n",
      "Iter 149760, Minibatch Loss= 0.033811, Training Accuracy= 0.99219\n",
      "Iter 151040, Minibatch Loss= 0.019391, Training Accuracy= 1.00000\n",
      "Iter 152320, Minibatch Loss= 0.036401, Training Accuracy= 0.99219\n",
      "Iter 153600, Minibatch Loss= 0.047275, Training Accuracy= 0.98438\n",
      "Iter 154880, Minibatch Loss= 0.031568, Training Accuracy= 0.99219\n",
      "Iter 156160, Minibatch Loss= 0.010254, Training Accuracy= 1.00000\n",
      "Iter 157440, Minibatch Loss= 0.027849, Training Accuracy= 0.99219\n",
      "Iter 158720, Minibatch Loss= 0.049120, Training Accuracy= 0.98438\n",
      "Iter 160000, Minibatch Loss= 0.051258, Training Accuracy= 0.97656\n",
      "Iter 161280, Minibatch Loss= 0.056321, Training Accuracy= 0.98438\n",
      "Iter 162560, Minibatch Loss= 0.026799, Training Accuracy= 0.99219\n",
      "Iter 163840, Minibatch Loss= 0.040336, Training Accuracy= 0.99219\n",
      "Iter 165120, Minibatch Loss= 0.010001, Training Accuracy= 1.00000\n",
      "Iter 166400, Minibatch Loss= 0.022688, Training Accuracy= 0.99219\n",
      "Iter 167680, Minibatch Loss= 0.019046, Training Accuracy= 1.00000\n",
      "Iter 168960, Minibatch Loss= 0.017084, Training Accuracy= 1.00000\n",
      "Iter 170240, Minibatch Loss= 0.040288, Training Accuracy= 0.99219\n",
      "Iter 171520, Minibatch Loss= 0.008380, Training Accuracy= 1.00000\n",
      "Iter 172800, Minibatch Loss= 0.016493, Training Accuracy= 1.00000\n",
      "Iter 174080, Minibatch Loss= 0.018098, Training Accuracy= 0.99219\n",
      "Iter 175360, Minibatch Loss= 0.043857, Training Accuracy= 0.98438\n",
      "Iter 176640, Minibatch Loss= 0.017058, Training Accuracy= 0.99219\n",
      "Iter 177920, Minibatch Loss= 0.017244, Training Accuracy= 0.99219\n",
      "Iter 179200, Minibatch Loss= 0.073025, Training Accuracy= 0.98438\n",
      "Iter 180480, Minibatch Loss= 0.009797, Training Accuracy= 1.00000\n",
      "Iter 181760, Minibatch Loss= 0.059403, Training Accuracy= 0.98438\n",
      "Iter 183040, Minibatch Loss= 0.015551, Training Accuracy= 1.00000\n",
      "Iter 184320, Minibatch Loss= 0.021322, Training Accuracy= 0.99219\n",
      "Iter 185600, Minibatch Loss= 0.026435, Training Accuracy= 0.99219\n",
      "Iter 186880, Minibatch Loss= 0.047229, Training Accuracy= 0.98438\n",
      "Iter 188160, Minibatch Loss= 0.015958, Training Accuracy= 1.00000\n",
      "Iter 189440, Minibatch Loss= 0.016632, Training Accuracy= 0.99219\n",
      "Iter 190720, Minibatch Loss= 0.015319, Training Accuracy= 0.99219\n",
      "Iter 192000, Minibatch Loss= 0.012767, Training Accuracy= 1.00000\n",
      "Iter 193280, Minibatch Loss= 0.005747, Training Accuracy= 1.00000\n",
      "Iter 194560, Minibatch Loss= 0.012543, Training Accuracy= 0.99219\n",
      "Iter 195840, Minibatch Loss= 0.004010, Training Accuracy= 1.00000\n",
      "Iter 197120, Minibatch Loss= 0.017265, Training Accuracy= 1.00000\n",
      "Iter 198400, Minibatch Loss= 0.016795, Training Accuracy= 0.99219\n",
      "Iter 199680, Minibatch Loss= 0.070128, Training Accuracy= 0.98438\n",
      "Iter 200960, Minibatch Loss= 0.023629, Training Accuracy= 0.99219\n",
      "Iter 202240, Minibatch Loss= 0.007272, Training Accuracy= 1.00000\n",
      "Iter 203520, Minibatch Loss= 0.054177, Training Accuracy= 0.97656\n",
      "Iter 204800, Minibatch Loss= 0.013781, Training Accuracy= 0.99219\n",
      "Iter 206080, Minibatch Loss= 0.029861, Training Accuracy= 0.99219\n",
      "Iter 207360, Minibatch Loss= 0.043794, Training Accuracy= 0.98438\n",
      "Iter 208640, Minibatch Loss= 0.058908, Training Accuracy= 0.96875\n",
      "Iter 209920, Minibatch Loss= 0.018102, Training Accuracy= 0.99219\n",
      "Iter 211200, Minibatch Loss= 0.036121, Training Accuracy= 0.99219\n",
      "Iter 212480, Minibatch Loss= 0.016953, Training Accuracy= 0.99219\n",
      "Iter 213760, Minibatch Loss= 0.038066, Training Accuracy= 0.99219\n",
      "Iter 215040, Minibatch Loss= 0.054120, Training Accuracy= 0.98438\n",
      "Iter 216320, Minibatch Loss= 0.021769, Training Accuracy= 0.99219\n",
      "Iter 217600, Minibatch Loss= 0.048861, Training Accuracy= 0.99219\n",
      "Iter 218880, Minibatch Loss= 0.065537, Training Accuracy= 0.98438\n",
      "Iter 220160, Minibatch Loss= 0.027499, Training Accuracy= 0.99219\n",
      "Iter 221440, Minibatch Loss= 0.050242, Training Accuracy= 0.98438\n",
      "Iter 222720, Minibatch Loss= 0.006632, Training Accuracy= 1.00000\n",
      "Iter 224000, Minibatch Loss= 0.032667, Training Accuracy= 0.99219\n",
      "Iter 225280, Minibatch Loss= 0.019455, Training Accuracy= 0.99219\n",
      "Iter 226560, Minibatch Loss= 0.044900, Training Accuracy= 0.99219\n",
      "Iter 227840, Minibatch Loss= 0.031077, Training Accuracy= 0.99219\n",
      "Iter 229120, Minibatch Loss= 0.010855, Training Accuracy= 1.00000\n",
      "Iter 230400, Minibatch Loss= 0.006106, Training Accuracy= 1.00000\n",
      "Iter 231680, Minibatch Loss= 0.067581, Training Accuracy= 0.98438\n",
      "Iter 232960, Minibatch Loss= 0.012322, Training Accuracy= 1.00000\n",
      "Iter 234240, Minibatch Loss= 0.049634, Training Accuracy= 0.99219\n",
      "Iter 235520, Minibatch Loss= 0.005258, Training Accuracy= 1.00000\n",
      "Iter 236800, Minibatch Loss= 0.005218, Training Accuracy= 1.00000\n",
      "Iter 238080, Minibatch Loss= 0.085512, Training Accuracy= 0.98438\n",
      "Iter 239360, Minibatch Loss= 0.017592, Training Accuracy= 0.99219\n",
      "Iter 240640, Minibatch Loss= 0.013181, Training Accuracy= 1.00000\n",
      "Iter 241920, Minibatch Loss= 0.008452, Training Accuracy= 1.00000\n",
      "Iter 243200, Minibatch Loss= 0.023587, Training Accuracy= 0.98438\n",
      "Iter 244480, Minibatch Loss= 0.005916, Training Accuracy= 1.00000\n",
      "Iter 245760, Minibatch Loss= 0.013021, Training Accuracy= 1.00000\n",
      "Iter 247040, Minibatch Loss= 0.014841, Training Accuracy= 1.00000\n",
      "Iter 248320, Minibatch Loss= 0.031358, Training Accuracy= 0.98438\n",
      "Iter 249600, Minibatch Loss= 0.014026, Training Accuracy= 1.00000\n",
      "Iter 250880, Minibatch Loss= 0.047005, Training Accuracy= 0.98438\n",
      "Iter 252160, Minibatch Loss= 0.043117, Training Accuracy= 0.99219\n",
      "Iter 253440, Minibatch Loss= 0.010123, Training Accuracy= 1.00000\n",
      "Iter 254720, Minibatch Loss= 0.054367, Training Accuracy= 0.98438\n",
      "Iter 256000, Minibatch Loss= 0.015496, Training Accuracy= 1.00000\n",
      "Iter 257280, Minibatch Loss= 0.013115, Training Accuracy= 1.00000\n",
      "Iter 258560, Minibatch Loss= 0.021396, Training Accuracy= 0.99219\n",
      "Iter 259840, Minibatch Loss= 0.016537, Training Accuracy= 1.00000\n",
      "Iter 261120, Minibatch Loss= 0.015130, Training Accuracy= 1.00000\n",
      "Iter 262400, Minibatch Loss= 0.034731, Training Accuracy= 0.99219\n",
      "Iter 263680, Minibatch Loss= 0.014816, Training Accuracy= 0.99219\n",
      "Iter 264960, Minibatch Loss= 0.033436, Training Accuracy= 0.99219\n",
      "Iter 266240, Minibatch Loss= 0.007916, Training Accuracy= 1.00000\n",
      "Iter 267520, Minibatch Loss= 0.011310, Training Accuracy= 1.00000\n",
      "Iter 268800, Minibatch Loss= 0.013055, Training Accuracy= 1.00000\n",
      "Iter 270080, Minibatch Loss= 0.010269, Training Accuracy= 1.00000\n",
      "Iter 271360, Minibatch Loss= 0.042330, Training Accuracy= 0.98438\n",
      "Iter 272640, Minibatch Loss= 0.058295, Training Accuracy= 0.98438\n",
      "Iter 273920, Minibatch Loss= 0.061431, Training Accuracy= 0.97656\n",
      "Iter 275200, Minibatch Loss= 0.038304, Training Accuracy= 0.99219\n",
      "Iter 276480, Minibatch Loss= 0.009228, Training Accuracy= 1.00000\n",
      "Iter 277760, Minibatch Loss= 0.006665, Training Accuracy= 1.00000\n",
      "Iter 279040, Minibatch Loss= 0.002181, Training Accuracy= 1.00000\n",
      "Iter 280320, Minibatch Loss= 0.025514, Training Accuracy= 0.99219\n",
      "Iter 281600, Minibatch Loss= 0.003732, Training Accuracy= 1.00000\n",
      "Iter 282880, Minibatch Loss= 0.035422, Training Accuracy= 0.98438\n",
      "Iter 284160, Minibatch Loss= 0.051324, Training Accuracy= 0.99219\n",
      "Iter 285440, Minibatch Loss= 0.008588, Training Accuracy= 1.00000\n",
      "Iter 286720, Minibatch Loss= 0.019754, Training Accuracy= 0.99219\n",
      "Iter 288000, Minibatch Loss= 0.016933, Training Accuracy= 1.00000\n",
      "Iter 289280, Minibatch Loss= 0.053230, Training Accuracy= 0.97656\n",
      "Iter 290560, Minibatch Loss= 0.030888, Training Accuracy= 0.98438\n",
      "Iter 291840, Minibatch Loss= 0.003138, Training Accuracy= 1.00000\n",
      "Iter 293120, Minibatch Loss= 0.019023, Training Accuracy= 0.99219\n",
      "Iter 294400, Minibatch Loss= 0.012501, Training Accuracy= 1.00000\n",
      "Iter 295680, Minibatch Loss= 0.044914, Training Accuracy= 0.98438\n",
      "Iter 296960, Minibatch Loss= 0.018419, Training Accuracy= 0.99219\n",
      "Iter 298240, Minibatch Loss= 0.035663, Training Accuracy= 0.99219\n",
      "Iter 299520, Minibatch Loss= 0.051243, Training Accuracy= 0.97656\n",
      "Iter 300800, Minibatch Loss= 0.011522, Training Accuracy= 1.00000\n",
      "Iter 302080, Minibatch Loss= 0.012197, Training Accuracy= 1.00000\n",
      "Iter 303360, Minibatch Loss= 0.008755, Training Accuracy= 1.00000\n",
      "Iter 304640, Minibatch Loss= 0.003571, Training Accuracy= 1.00000\n",
      "Iter 305920, Minibatch Loss= 0.015191, Training Accuracy= 0.99219\n",
      "Iter 307200, Minibatch Loss= 0.009410, Training Accuracy= 1.00000\n",
      "Iter 308480, Minibatch Loss= 0.013586, Training Accuracy= 1.00000\n",
      "Iter 309760, Minibatch Loss= 0.039625, Training Accuracy= 0.99219\n",
      "Iter 311040, Minibatch Loss= 0.007284, Training Accuracy= 1.00000\n",
      "Iter 312320, Minibatch Loss= 0.065490, Training Accuracy= 0.98438\n",
      "Iter 313600, Minibatch Loss= 0.010549, Training Accuracy= 1.00000\n",
      "Iter 314880, Minibatch Loss= 0.006339, Training Accuracy= 1.00000\n",
      "Iter 316160, Minibatch Loss= 0.087008, Training Accuracy= 0.98438\n",
      "Iter 317440, Minibatch Loss= 0.038446, Training Accuracy= 0.99219\n",
      "Iter 318720, Minibatch Loss= 0.014252, Training Accuracy= 0.99219\n",
      "Iter 320000, Minibatch Loss= 0.053700, Training Accuracy= 0.97656\n",
      "Iter 321280, Minibatch Loss= 0.025790, Training Accuracy= 0.99219\n",
      "Iter 322560, Minibatch Loss= 0.024727, Training Accuracy= 0.99219\n",
      "Iter 323840, Minibatch Loss= 0.037522, Training Accuracy= 0.99219\n",
      "Iter 325120, Minibatch Loss= 0.010564, Training Accuracy= 0.99219\n",
      "Iter 326400, Minibatch Loss= 0.004083, Training Accuracy= 1.00000\n",
      "Iter 327680, Minibatch Loss= 0.020118, Training Accuracy= 0.99219\n",
      "Iter 328960, Minibatch Loss= 0.017964, Training Accuracy= 1.00000\n",
      "Iter 330240, Minibatch Loss= 0.026689, Training Accuracy= 0.98438\n",
      "Iter 331520, Minibatch Loss= 0.032083, Training Accuracy= 0.98438\n",
      "Iter 332800, Minibatch Loss= 0.029263, Training Accuracy= 0.99219\n",
      "Iter 334080, Minibatch Loss= 0.006240, Training Accuracy= 1.00000\n",
      "Iter 335360, Minibatch Loss= 0.039239, Training Accuracy= 0.99219\n",
      "Iter 336640, Minibatch Loss= 0.013599, Training Accuracy= 0.99219\n",
      "Iter 337920, Minibatch Loss= 0.007852, Training Accuracy= 1.00000\n",
      "Iter 339200, Minibatch Loss= 0.014462, Training Accuracy= 0.99219\n",
      "Iter 340480, Minibatch Loss= 0.003984, Training Accuracy= 1.00000\n",
      "Iter 341760, Minibatch Loss= 0.001476, Training Accuracy= 1.00000\n",
      "Iter 343040, Minibatch Loss= 0.006336, Training Accuracy= 1.00000\n",
      "Iter 344320, Minibatch Loss= 0.006624, Training Accuracy= 1.00000\n",
      "Iter 345600, Minibatch Loss= 0.044325, Training Accuracy= 0.98438\n",
      "Iter 346880, Minibatch Loss= 0.006924, Training Accuracy= 1.00000\n",
      "Iter 348160, Minibatch Loss= 0.006065, Training Accuracy= 1.00000\n",
      "Iter 349440, Minibatch Loss= 0.035475, Training Accuracy= 0.98438\n",
      "Iter 350720, Minibatch Loss= 0.022661, Training Accuracy= 0.99219\n",
      "Iter 352000, Minibatch Loss= 0.024836, Training Accuracy= 0.99219\n",
      "Iter 353280, Minibatch Loss= 0.020724, Training Accuracy= 0.99219\n",
      "Iter 354560, Minibatch Loss= 0.010410, Training Accuracy= 1.00000\n",
      "Iter 355840, Minibatch Loss= 0.030142, Training Accuracy= 0.99219\n",
      "Iter 357120, Minibatch Loss= 0.049620, Training Accuracy= 0.99219\n",
      "Iter 358400, Minibatch Loss= 0.002578, Training Accuracy= 1.00000\n",
      "Iter 359680, Minibatch Loss= 0.019059, Training Accuracy= 0.99219\n",
      "Iter 360960, Minibatch Loss= 0.040333, Training Accuracy= 0.99219\n",
      "Iter 362240, Minibatch Loss= 0.041492, Training Accuracy= 0.99219\n",
      "Iter 363520, Minibatch Loss= 0.006276, Training Accuracy= 1.00000\n",
      "Iter 364800, Minibatch Loss= 0.026490, Training Accuracy= 0.99219\n",
      "Iter 366080, Minibatch Loss= 0.004824, Training Accuracy= 1.00000\n",
      "Iter 367360, Minibatch Loss= 0.005625, Training Accuracy= 1.00000\n",
      "Iter 368640, Minibatch Loss= 0.035034, Training Accuracy= 0.97656\n",
      "Iter 369920, Minibatch Loss= 0.017454, Training Accuracy= 1.00000\n",
      "Iter 371200, Minibatch Loss= 0.006782, Training Accuracy= 1.00000\n",
      "Iter 372480, Minibatch Loss= 0.058053, Training Accuracy= 0.99219\n",
      "Iter 373760, Minibatch Loss= 0.011823, Training Accuracy= 1.00000\n",
      "Iter 375040, Minibatch Loss= 0.008092, Training Accuracy= 1.00000\n",
      "Iter 376320, Minibatch Loss= 0.031429, Training Accuracy= 0.99219\n",
      "Iter 377600, Minibatch Loss= 0.032878, Training Accuracy= 0.99219\n",
      "Iter 378880, Minibatch Loss= 0.008464, Training Accuracy= 1.00000\n",
      "Iter 380160, Minibatch Loss= 0.007922, Training Accuracy= 1.00000\n",
      "Iter 381440, Minibatch Loss= 0.010211, Training Accuracy= 1.00000\n",
      "Iter 382720, Minibatch Loss= 0.018454, Training Accuracy= 0.99219\n",
      "Iter 384000, Minibatch Loss= 0.013957, Training Accuracy= 0.99219\n",
      "Iter 385280, Minibatch Loss= 0.007153, Training Accuracy= 1.00000\n",
      "Iter 386560, Minibatch Loss= 0.004658, Training Accuracy= 1.00000\n",
      "Iter 387840, Minibatch Loss= 0.006286, Training Accuracy= 1.00000\n",
      "Iter 389120, Minibatch Loss= 0.004082, Training Accuracy= 1.00000\n",
      "Iter 390400, Minibatch Loss= 0.005557, Training Accuracy= 1.00000\n",
      "Iter 391680, Minibatch Loss= 0.001486, Training Accuracy= 1.00000\n",
      "Iter 392960, Minibatch Loss= 0.028721, Training Accuracy= 0.99219\n",
      "Iter 394240, Minibatch Loss= 0.014776, Training Accuracy= 0.99219\n",
      "Iter 395520, Minibatch Loss= 0.008071, Training Accuracy= 1.00000\n",
      "Iter 396800, Minibatch Loss= 0.008877, Training Accuracy= 1.00000\n",
      "Iter 398080, Minibatch Loss= 0.020136, Training Accuracy= 0.98438\n",
      "Iter 399360, Minibatch Loss= 0.044139, Training Accuracy= 0.99219\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.9878\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "max_samples = 400000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 28 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28 # timesteps\n",
    "n_hidden = 256 # hidden layer num of features\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    # Hidden layer weights => 2*n_hidden because of foward + backward cells\n",
    "    'out': tf.Variable(tf.random_normal([2*n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def BiRNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `bidirectional_rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "    \n",
    "    # Permuting batch_size and n_steps\n",
    "    x = tf.transpose(x, [1, 0, 2])\n",
    "    # Reshape to (n_steps*batch_size, n_input)\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.split(x, n_steps)\n",
    "\n",
    "    # Define lstm cells with tensorflow\n",
    "    # Forward direction cell\n",
    "    lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    # Backward direction cell\n",
    "    lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "#    try:\n",
    "    outputs, _, _ = tf.contrib.rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                           dtype=tf.float32)\n",
    "#    except Exception: # Old TensorFlow version only returns outputs not states\n",
    "#        outputs = rnn.bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "#                                        dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "    \n",
    "\n",
    "pred = BiRNN(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < max_samples:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 10000\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
