{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 100 , average reward of last 100 episode 2.18\n",
      "episode 200 , average reward of last 100 episode 1.51\n",
      "episode 300 , average reward of last 100 episode 1.72\n",
      "episode 400 , average reward of last 100 episode 1.0\n",
      "episode 500 , average reward of last 100 episode 0.84\n",
      "episode 600 , average reward of last 100 episode 0.96\n",
      "episode 700 , average reward of last 100 episode 1.33\n",
      "episode 800 , average reward of last 100 episode 1.02\n",
      "episode 900 , average reward of last 100 episode 1.43\n",
      "episode 1000 , average reward of last 100 episode 1.42\n",
      "Saved Model\n",
      "episode 1100 , average reward of last 100 episode 1.79\n",
      "episode 1200 , average reward of last 100 episode 1.64\n",
      "episode 1300 , average reward of last 100 episode 1.87\n",
      "episode 1400 , average reward of last 100 episode 1.55\n",
      "episode 1500 , average reward of last 100 episode 2.54\n",
      "episode 1600 , average reward of last 100 episode 2.14\n",
      "episode 1700 , average reward of last 100 episode 3.35\n",
      "episode 1800 , average reward of last 100 episode 4.47\n",
      "episode 1900 , average reward of last 100 episode 5.35\n",
      "episode 2000 , average reward of last 100 episode 6.58\n",
      "Saved Model\n",
      "episode 2100 , average reward of last 100 episode 8.55\n",
      "episode 2200 , average reward of last 100 episode 9.39\n",
      "episode 2300 , average reward of last 100 episode 11.87\n",
      "episode 2400 , average reward of last 100 episode 13.23\n",
      "episode 2500 , average reward of last 100 episode 14.04\n",
      "episode 2600 , average reward of last 100 episode 16.19\n",
      "episode 2700 , average reward of last 100 episode 16.47\n",
      "episode 2800 , average reward of last 100 episode 18.06\n",
      "episode 2900 , average reward of last 100 episode 17.61\n",
      "episode 3000 , average reward of last 100 episode 19.26\n",
      "Saved Model\n",
      "episode 3100 , average reward of last 100 episode 19.83\n",
      "episode 3200 , average reward of last 100 episode 19.66\n",
      "episode 3300 , average reward of last 100 episode 20.38\n",
      "episode 3400 , average reward of last 100 episode 20.89\n",
      "episode 3500 , average reward of last 100 episode 21.06\n",
      "episode 3600 , average reward of last 100 episode 20.39\n",
      "episode 3700 , average reward of last 100 episode 21.25\n",
      "episode 3800 , average reward of last 100 episode 21.15\n",
      "episode 3900 , average reward of last 100 episode 21.46\n",
      "episode 4000 , average reward of last 100 episode 21.04\n",
      "Saved Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from gridworld import gameEnv\n",
    "env = gameEnv(size=5)\n",
    "\n",
    "\n",
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.conv3,num_outputs=512,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = tf.contrib.layers.flatten(self.streamAC)\n",
    "        self.streamV = tf.contrib.layers.flatten(self.streamVC)\n",
    "        self.AW = tf.Variable(tf.random_normal([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(tf.random_normal([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,reduction_indices=1,keepdims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), reduction_indices=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)\n",
    "        \n",
    "\n",
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])\n",
    "        \n",
    "        \n",
    "\n",
    "def processState(states):\n",
    "    return np.reshape(states,[21168])\n",
    "\n",
    "\n",
    "     \n",
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(\n",
    "                tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "anneling_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 4000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network\n",
    "\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/anneling_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "saver = tf.train.Saver()\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "#%%\n",
    "with tf.Session() as sess:\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    sess.run(init)\n",
    "    updateTarget(targetOps,sess) #Set the target network to be equal to the primary network.\n",
    "    for i in range(num_episodes+1):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    A = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    doubleQ = Q[range(batch_size),A]\n",
    "                    targetQ = trainBatch[:,2] + y*doubleQ\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),\n",
    "                                   mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Set the target network to be equal to the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "                break\n",
    "        \n",
    "        #Get all experiences from this episode and discount their rewards.\n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model.\n",
    "\n",
    "        if i>0 and i % 100 == 0:\n",
    "            print('episode',i,', average reward of last 100 episode',np.mean(rList[-100:]))\n",
    "        if i>0 and i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.cptk')\n",
    "            print(\"Saved Model\")            \n",
    "    saver.save(sess,path+'/model-'+str(i)+'.cptk')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f669d66f898>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
